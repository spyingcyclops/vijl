{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "79e3e8a47435f915"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:08:55.880505Z",
     "start_time": "2024-11-26T13:08:50.025810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Load and Preprocess Data\n",
    "database_path = \"data/data.db\"\n",
    "conn = sqlite3.connect(database_path)\n",
    "query = open('data/fetch_all.sql', 'r').read()\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df.head(), df.info()\n",
    "\n",
    "# Map 'yes' to 1, 'no' to 0, and 'unknown' to NaN\n",
    "df['y'] = df['y'].map({'no': 0, 'yes': 1, 'unknown': None})\n",
    "\n",
    "# Drop irrelevant columns\n",
    "irrelevant_columns = ['client_id', 'account_id', 'campaign_id', 'outcome_id']\n",
    "data_cleaned = df.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = data_cleaned.select_dtypes(include=['object']).columns\n",
    "one_hot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_categorical = one_hot_encoder.fit_transform(data_cleaned[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Merge encoded features back into the dataset\n",
    "data_cleaned = data_cleaned.drop(columns=categorical_features).reset_index(drop=True)\n",
    "data_cleaned = pd.concat([data_cleaned, encoded_df], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = data_cleaned.select_dtypes(include=['int64', 'float64']).columns.drop('y', errors='ignore')\n",
    "scaler = StandardScaler()\n",
    "data_cleaned[numerical_features] = scaler.fit_transform(data_cleaned[numerical_features])\n",
    "\n",
    "# Step 2: Train the Model\n",
    "# Use rows with known 'y' values for training\n",
    "data_train = data_cleaned[data_cleaned['y'].notnull()]\n",
    "X_train = data_train.drop(columns=['y'])\n",
    "y_train = data_train['y']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Step 3: Model Selection with LazyPredict\n",
    "lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = lazy_clf.fit(X_train_split, X_test_split, y_train_split, y_test_split)\n",
    "models = models.sort_values(by='Accuracy', ascending=False)\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "print(models)\n",
    "# Identify the best model based on accuracy\n",
    "best_model_name = models.index[0]\n",
    "print(f\"Best model from LazyPredict: {best_model_name}\")\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Step 4: Predict Probabilities for the Full Dataset\n",
    "X_full = data_cleaned.drop(columns=['y'])\n",
    "data_cleaned['Probability'] = model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "# Select the top 5,000 clients\n",
    "selected_clients = data_cleaned.sort_values(by='Probability', ascending=False).head(5000)\n",
    "\n",
    "# Step 5: Save Selected Client IDs to CSV\n",
    "selected_client_ids = df.loc[selected_clients.index, ['client_id']]\n",
    "selected_client_ids.to_csv(\"second_phase_target.csv\", index=False, header=['target'])\n",
    "\n",
    "print(\"Selected client IDs saved to 'second_phase_target.csv'.\")"
   ],
   "id": "56a8ce8d5cda333c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   client_id    45211 non-null  int64  \n",
      " 1   age          45211 non-null  int64  \n",
      " 2   job          45211 non-null  object \n",
      " 3   marital      45211 non-null  object \n",
      " 4   education    45211 non-null  object \n",
      " 5   account_id   45211 non-null  int64  \n",
      " 6   in_default   45211 non-null  object \n",
      " 7   balance      45211 non-null  float64\n",
      " 8   housing      45211 non-null  object \n",
      " 9   loan         45211 non-null  object \n",
      " 10  contact      45211 non-null  object \n",
      " 11  campaign_id  45211 non-null  int64  \n",
      " 12  day          45211 non-null  int64  \n",
      " 13  month        45211 non-null  object \n",
      " 14  duration     45211 non-null  int64  \n",
      " 15  campaign     45211 non-null  int64  \n",
      " 16  pdays        45211 non-null  int64  \n",
      " 17  previous     45211 non-null  int64  \n",
      " 18  outcome_id   45211 non-null  int64  \n",
      " 19  poutcome     45211 non-null  object \n",
      " 20  y            45211 non-null  object \n",
      "dtypes: float64(1), int64(10), object(10)\n",
      "memory usage: 7.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 417, number of negative: 3199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 956\n",
      "[LightGBM] [Info] Number of data points in the train set: 3616, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115321 -> initscore=-2.037507\n",
      "[LightGBM] [Info] Start training from score -2.037507\n",
      "                                  Accuracy  Balanced Accuracy      ROC AUC  \\\n",
      "Model                                                                        \n",
      "RidgeClassifierCV             0.8950276243       0.6227552098 0.6227552098   \n",
      "RidgeClassifier               0.8950276243       0.6227552098 0.6227552098   \n",
      "LGBMClassifier                0.8928176796       0.6591580236 0.6591580236   \n",
      "LinearSVC                     0.8928176796       0.6298737155 0.6298737155   \n",
      "CalibratedClassifierCV        0.8917127072       0.6292494958 0.6292494958   \n",
      "LogisticRegression            0.8906077348       0.6328087487 0.6328087487   \n",
      "SVC                           0.8895027624       0.5861663305 0.5861663305   \n",
      "SGDClassifier                 0.8883977901       0.6357437818 0.6357437818   \n",
      "AdaBoostClassifier            0.8883977901       0.6399272544 0.6399272544   \n",
      "RandomForestClassifier        0.8883977901       0.5855421108 0.5855421108   \n",
      "ExtraTreesClassifier          0.8883977901       0.6022760012 0.6022760012   \n",
      "XGBClassifier                 0.8861878453       0.6637796504 0.6637796504   \n",
      "LinearDiscriminantAnalysis    0.8861878453       0.6595961779 0.6595961779   \n",
      "DummyClassifier               0.8850828729       0.5000000000 0.5000000000   \n",
      "BaggingClassifier             0.8795580110       0.6391169692 0.6391169692   \n",
      "KNeighborsClassifier          0.8740331492       0.5690603092 0.5690603092   \n",
      "DecisionTreeClassifier        0.8740331492       0.6778305964 0.6778305964   \n",
      "Perceptron                    0.8640883978       0.6889465092 0.6889465092   \n",
      "QuadraticDiscriminantAnalysis 0.8574585635       0.6601003553 0.6601003553   \n",
      "LabelSpreading                0.8497237569       0.6097126188 0.6097126188   \n",
      "LabelPropagation              0.8497237569       0.6097126188 0.6097126188   \n",
      "PassiveAggressiveClassifier   0.8453038674       0.6406835206 0.6406835206   \n",
      "BernoulliNB                   0.8441988950       0.6400593009 0.6400593009   \n",
      "GaussianNB                    0.8419889503       0.6597282243 0.6597282243   \n",
      "ExtraTreeClassifier           0.8342541436       0.6218909056 0.6218909056   \n",
      "NearestCentroid               0.8165745856       0.7499579852 0.7499579852   \n",
      "\n",
      "                                  F1 Score   Time Taken  \n",
      "Model                                                    \n",
      "RidgeClassifierCV             0.8770182803 0.0348079205  \n",
      "RidgeClassifier               0.8770182803 0.0179858208  \n",
      "LGBMClassifier                0.8824317380 0.0929944515  \n",
      "LinearSVC                     0.8770625339 0.0324738026  \n",
      "CalibratedClassifierCV        0.8762173721 0.0986950397  \n",
      "LogisticRegression            0.8761994967 0.0195598602  \n",
      "SVC                           0.8649173634 0.2438554764  \n",
      "SGDClassifier                 0.8753143146 0.0333027840  \n",
      "AdaBoostClassifier            0.8760905980 0.2006237507  \n",
      "RandomForestClassifier        0.8641224397 0.3496766090  \n",
      "ExtraTreesClassifier          0.8682841488 0.3092741966  \n",
      "XGBClassifier                 0.8786422881 0.0998771191  \n",
      "LinearDiscriminantAnalysis    0.8779802436 0.2346212864  \n",
      "DummyClassifier               0.8311270589 0.0115022659  \n",
      "BaggingClassifier             0.8701540344 0.1692872047  \n",
      "KNeighborsClassifier          0.8518801837 0.1770346165  \n",
      "DecisionTreeClassifier        0.8723973671 0.0338273048  \n",
      "Perceptron                    0.8670318639 0.0137889385  \n",
      "QuadraticDiscriminantAnalysis 0.8589084457 0.0275285244  \n",
      "LabelSpreading                0.8463950197 0.6440320015  \n",
      "LabelPropagation              0.8463950197 0.4646866322  \n",
      "PassiveAggressiveClassifier   0.8483660892 0.0166666508  \n",
      "BernoulliNB                   0.8475731123 0.0170278549  \n",
      "GaussianNB                    0.8487044925 0.0162377357  \n",
      "ExtraTreeClassifier           0.8387497466 0.0250234604  \n",
      "NearestCentroid               0.8396902648 0.0136632919  \n",
      "Best model from LazyPredict: RidgeClassifierCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected client IDs saved to 'second_phase_target.csv'.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
