{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module prepares the data, splits into train/test, and performs undersampling to balance the data set. \n",
    "Then it trains and compares these machine learning models:\n",
    "- Logistic Regression\n",
    "- Ridge Classifier\n",
    "- Random Forest Classifier\n",
    "- K-Neighbours Classifier\n",
    "-\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    database_path = \"data/data.db\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    query = open('data/fetch_all.sql', 'r').read()\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "except (sqlite3.Error, FileNotFoundError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "\n",
    "# Filter only rows with 'yes' or 'no' in the 'y' column\n",
    "df = df[df['y'].isin(['no', 'yes'])]\n",
    "\n",
    "# Drop specified columns\n",
    "df = df.drop(columns=['client_id', 'account_id', 'campaign_id', 'outcome_id', 'previous', 'poutcome', 'month'])\n",
    "\n",
    "# Binning day of the week into Early, Mid, and Late\n",
    "\n",
    "bins = [0, 9, 19, 31]\n",
    "labels = ['early', 'mid', 'late']\n",
    "df['day_bin'] = pd.cut(df['day'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Binning age into common bins\n",
    "age_bins = [0, 20, 30, 40, 50, 60, 100]\n",
    "age_labels = ['<20', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "df['age_bin'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age   balance       day  duration  campaign     pdays  \\\n",
      "0  0.078478 -0.472088 -1.323585  0.446598 -0.576829 -0.407218   \n",
      "1  0.173040 -0.275697 -1.323585 -0.804230 -0.576829 -0.407218   \n",
      "2  1.496912 -0.418920 -1.323585 -0.346234 -0.576829 -0.407218   \n",
      "3  1.496912 -0.193951 -1.323585 -0.149950 -0.576829 -0.407218   \n",
      "4  1.686036 -0.472753 -1.323585 -0.146102 -0.576829 -0.407218   \n",
      "\n",
      "   job_blue-collar  job_entrepreneur  job_housemaid  job_management  ...  \\\n",
      "0              0.0               1.0            0.0             0.0  ...   \n",
      "1              0.0               0.0            0.0             0.0  ...   \n",
      "2              0.0               0.0            0.0             0.0  ...   \n",
      "3              0.0               0.0            0.0             0.0  ...   \n",
      "4              1.0               0.0            0.0             0.0  ...   \n",
      "\n",
      "   marital_single  education_secondary  education_tertiary  education_unknown  \\\n",
      "0             0.0                  0.0                 1.0                0.0   \n",
      "1             1.0                  1.0                 0.0                0.0   \n",
      "2             0.0                  1.0                 0.0                0.0   \n",
      "3             0.0                  1.0                 0.0                0.0   \n",
      "4             0.0                  1.0                 0.0                0.0   \n",
      "\n",
      "   in_default_yes  housing_yes  loan_yes  contact_telephone  contact_unknown  \\\n",
      "0             1.0          1.0       0.0                0.0              1.0   \n",
      "1             0.0          1.0       0.0                0.0              1.0   \n",
      "2             0.0          1.0       0.0                0.0              1.0   \n",
      "3             0.0          0.0       1.0                0.0              1.0   \n",
      "4             0.0          1.0       0.0                0.0              1.0   \n",
      "\n",
      "   y_yes  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    0.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "scaled_numeric_features = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Create a DataFrame with the scaled numerical features\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric_features, columns=numerical_columns)\n",
    "\n",
    "# Concatenate the scaled numerical features and the encoded categorical features\n",
    "df_enc = pd.concat([scaled_numeric_df, encoded_df], axis=1)\n",
    "\n",
    "print(df_enc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming df_encoded_min_max_scaled is the dataframe to be split\n",
    "X = df_enc.drop(columns=['y_yes'])\n",
    "y = df_enc['y_yes']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6400, 27)\n",
      "X_test shape: (1600, 27)\n",
      "y_train shape: (6400,)\n",
      "y_test shape: (1600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets with 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Cross-Validation Score: 0.8084374999999999\n",
      "Test Accuracy: 0.8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80       803\n",
      "         1.0       0.80      0.80      0.80       797\n",
      "\n",
      "    accuracy                           0.80      1600\n",
      "   macro avg       0.80      0.80      0.80      1600\n",
      "weighted avg       0.80      0.80      0.80      1600\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Ridge Classifier\n",
      "Best Parameters: N/A (RidgeClassifierCV performs internal CV)\n",
      "Cross-Validation Score: 0.8021875\n",
      "Test Accuracy: 0.79\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79       803\n",
      "         1.0       0.79      0.79      0.79       797\n",
      "\n",
      "    accuracy                           0.79      1600\n",
      "   macro avg       0.79      0.79      0.79      1600\n",
      "weighted avg       0.79      0.79      0.79      1600\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Cross-Validation Score: 0.94046875\n",
      "Test Accuracy: 0.948125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       803\n",
      "         1.0       0.94      0.95      0.95       797\n",
      "\n",
      "    accuracy                           0.95      1600\n",
      "   macro avg       0.95      0.95      0.95      1600\n",
      "weighted avg       0.95      0.95      0.95      1600\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model: K-Neighbors Classifier\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Cross-Validation Score: 0.9253125000000001\n",
      "Test Accuracy: 0.92875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92       803\n",
      "         1.0       0.88      1.00      0.93       797\n",
      "\n",
      "    accuracy                           0.93      1600\n",
      "   macro avg       0.94      0.93      0.93      1600\n",
      "weighted avg       0.94      0.93      0.93      1600\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'Ridge Classifier': {\n",
    "        'model': RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], cv=5),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'K-Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7, 9],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and hyperparameter tuning\n",
    "results = []\n",
    "for model_name, model_info in models.items():\n",
    "    if model_name == 'Ridge Classifier':\n",
    "        clf = model_info['model']\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Parameters': 'N/A (RidgeClassifierCV performs internal CV)',\n",
    "            'Cross-Validation Score': clf.score(X_train, y_train),\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Classification Report': classification_report(y_test, y_pred)\n",
    "        })\n",
    "    else:\n",
    "        clf = GridSearchCV(model_info['model'], model_info['params'], cv=5, scoring='accuracy')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Parameters': clf.best_params_,\n",
    "            'Cross-Validation Score': clf.best_score_,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Classification Report': classification_report(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    print(f\"Cross-Validation Score: {result['Cross-Validation Score']}\")\n",
    "    print(f\"Test Accuracy: {result['Test Accuracy']}\")\n",
    "    print(f\"Classification Report:\\n{result['Classification Report']}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
