{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module performs exploratory data analysis (EDA) on the data. It focuses on records with 'yes' or 'no' in the 'y' column. \n",
    "It tests the data for multicollinearity.\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "try:\n",
    "    database_path = \"data/data.db\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    query = open('data/fetch_all.sql', 'r').read()\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "except (sqlite3.Error, FileNotFoundError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "\n",
    "# Filter only rows with 'yes' or 'no' in the 'y' column\n",
    "df = df[df['y'].isin(['no', 'yes'])]\n",
    "\n",
    "# Drop specified columns\n",
    "df = df.drop(columns=['client_id', 'account_id', 'campaign_id', 'outcome_id', 'previous', 'poutcome'])\n",
    "\n",
    "# Binning day of the week into Early, Mid, and Late\n",
    "\n",
    "bins = [0, 9, 19, 31]\n",
    "labels = ['early', 'mid', 'late']\n",
    "df['day_bin'] = pd.cut(df['day'], bins=bins, labels=labels, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_columns = ['job', 'marital', 'education', 'in_default', 'housing', 'loan', 'contact', 'month', 'y']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Drop the original categorical columns from df and concatenate the encoded features\n",
    "df_encoded = pd.concat([df.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the encoded dataframe\n",
    "df_encoded_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "df_encoded_scaled = pd.DataFrame(df_encoded_scaled, columns=df_encoded.columns)\n",
    "\n",
    "print(df_encoded_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the encoded dataframe\n",
    "df_encoded_min_max_scaled = min_max_scaler.fit_transform(encoded_df)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "df_encoded_min_max_scaled = pd.DataFrame(df_encoded_min_max_scaled, columns=encoded_df.columns)\n",
    "\n",
    "print(df_encoded_min_max_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6868, 38)\n",
      "X_test shape: (1718, 38)\n",
      "y_train shape: (6868,)\n",
      "y_test shape: (1718,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_encoded_scaled is the dataframe to be split\n",
    "X = df_encoded_scaled.drop(columns=['y_yes'])\n",
    "y = df_encoded_scaled['y_yes']\n",
    "\n",
    "# Split the data into train and test sets with 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
