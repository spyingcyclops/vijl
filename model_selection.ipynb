{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module prepares the data, splits into train/test, and performs undersampling to balance the data set. \n",
    "Then it trains and compares these machine learning models:\n",
    "- Logistic Regression\n",
    "- Ridge Classifier\n",
    "- Random Forest Classifier\n",
    "- K-Neighbours Classifier\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "try:\n",
    "    database_path = \"data/data.db\"\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    query = open('data/fetch_all.sql', 'r').read()\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "except (sqlite3.Error, FileNotFoundError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "\n",
    "# Filter only rows with 'yes' or 'no' in the 'y' column\n",
    "df = df[df['y'].isin(['no', 'yes'])]\n",
    "\n",
    "# Drop specified columns\n",
    "df = df.drop(columns=['client_id', 'account_id', 'campaign_id', 'outcome_id', 'previous', 'poutcome', 'month'])\n",
    "\n",
    "# Binning day of the week into Early, Mid, and Late\n",
    "\n",
    "bins = [0, 9, 19, 31]\n",
    "labels = ['early', 'mid', 'late']\n",
    "df['day_bin'] = pd.cut(df['day'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Binning age into common bins\n",
    "age_bins = [0, 20, 30, 40, 50, 60, 100]\n",
    "age_labels = ['<20', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "df['age_bin'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age   balance       day  duration  campaign     pdays  \\\n",
      "0  0.078478 -0.472088 -1.323585  0.446598 -0.576829 -0.407218   \n",
      "1  0.173040 -0.275697 -1.323585 -0.804230 -0.576829 -0.407218   \n",
      "2  1.496912 -0.418920 -1.323585 -0.346234 -0.576829 -0.407218   \n",
      "3  1.496912 -0.193951 -1.323585 -0.149950 -0.576829 -0.407218   \n",
      "4  1.686036 -0.472753 -1.323585 -0.146102 -0.576829 -0.407218   \n",
      "\n",
      "   job_blue-collar  job_entrepreneur  job_housemaid  job_management  ...  \\\n",
      "0              0.0               1.0            0.0             0.0  ...   \n",
      "1              0.0               0.0            0.0             0.0  ...   \n",
      "2              0.0               0.0            0.0             0.0  ...   \n",
      "3              0.0               0.0            0.0             0.0  ...   \n",
      "4              1.0               0.0            0.0             0.0  ...   \n",
      "\n",
      "   marital_single  education_secondary  education_tertiary  education_unknown  \\\n",
      "0             0.0                  0.0                 1.0                0.0   \n",
      "1             1.0                  1.0                 0.0                0.0   \n",
      "2             0.0                  1.0                 0.0                0.0   \n",
      "3             0.0                  1.0                 0.0                0.0   \n",
      "4             0.0                  1.0                 0.0                0.0   \n",
      "\n",
      "   in_default_yes  housing_yes  loan_yes  contact_telephone  contact_unknown  \\\n",
      "0             1.0          1.0       0.0                0.0              1.0   \n",
      "1             0.0          1.0       0.0                0.0              1.0   \n",
      "2             0.0          1.0       0.0                0.0              1.0   \n",
      "3             0.0          0.0       1.0                0.0              1.0   \n",
      "4             0.0          1.0       0.0                0.0              1.0   \n",
      "\n",
      "   y_yes  \n",
      "0    0.0  \n",
      "1    0.0  \n",
      "2    0.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Create a DataFrame with the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "scaled_numeric_features = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Create a DataFrame with the scaled numerical features\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric_features, columns=numerical_columns)\n",
    "\n",
    "# Concatenate the scaled numerical features and the encoded categorical features\n",
    "df_enc = pd.concat([scaled_numeric_df, encoded_df], axis=1)\n",
    "\n",
    "print(df_enc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (833, 27)\n",
      "X_test shape: (209, 27)\n",
      "y_train shape: (833,)\n",
      "y_test shape: (209,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Assuming df_encoded_scaled is the dataframe to be split\n",
    "X = df_enc.drop(columns=['y_yes'])\n",
    "y = df_enc['y_yes']\n",
    "\n",
    "# Apply undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into train and test sets with 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'Ridge Classifier': {\n",
    "        'model': RidgeClassifierCV(alphas=[0.1, 1.0, 10.0], cv=5),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'K-Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7, 9],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform cross-validation and hyperparameter tuning\n",
    "results = []\n",
    "for model_name, model_info in models.items():\n",
    "    if model_name == 'Ridge Classifier':\n",
    "        clf = model_info['model']\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Parameters': 'N/A (RidgeClassifierCV performs internal CV)',\n",
    "            'Cross-Validation Score': clf.score(X_train, y_train),\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Classification Report': classification_report(y_test, y_pred)\n",
    "        })\n",
    "    else:\n",
    "        clf = GridSearchCV(model_info['model'], model_info['params'], cv=5, scoring='accuracy')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Parameters': clf.best_params_,\n",
    "            'Cross-Validation Score': clf.best_score_,\n",
    "            'Test Accuracy': accuracy,\n",
    "            'Classification Report': classification_report(y_test, y_pred)\n",
    "        })\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    print(f\"Cross-Validation Score: {result['Cross-Validation Score']}\")\n",
    "    print(f\"Test Accuracy: {result['Test Accuracy']}\")\n",
    "    print(f\"Classification Report:\\n{result['Classification Report']}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
